{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1 - 速通 Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T16:21:21.012962Z",
     "iopub.status.busy": "2024-07-11T16:21:21.012776Z",
     "iopub.status.idle": "2024-07-11T16:21:25.462494Z",
     "shell.execute_reply": "2024-07-11T16:21:25.461961Z",
     "shell.execute_reply.started": "2024-07-11T16:21:21.012944Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from torchtext) (1.26.3)\n",
      "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/site-packages (from torchtext) (2.3.0+cu121)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from torchtext) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from torchtext) (4.66.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (3.1.4)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (3.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (2024.2.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (1.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from torch>=2.3.0->torchtext) (4.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->torchtext) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->torchtext) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->torchtext) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->torchtext) (3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T16:21:25.464048Z",
     "iopub.status.busy": "2024-07-11T16:21:25.463761Z",
     "iopub.status.idle": "2024-07-11T16:21:26.605108Z",
     "shell.execute_reply": "2024-07-11T16:21:26.604317Z",
     "shell.execute_reply.started": "2024-07-11T16:21:25.464028Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "import random\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T16:21:26.606879Z",
     "iopub.status.busy": "2024-07-11T16:21:26.606308Z",
     "iopub.status.idle": "2024-07-11T16:21:26.617226Z",
     "shell.execute_reply": "2024-07-11T16:21:26.616514Z",
     "shell.execute_reply.started": "2024-07-11T16:21:26.606846Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义数据集类\n",
    "# 修改TranslationDataset类以处理术语\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, filename, terminology):\n",
    "        self.data = []\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                en, zh = line.strip().split('\\t')\n",
    "                self.data.append((en, zh))\n",
    "        \n",
    "        self.terminology = terminology\n",
    "        \n",
    "        # 创建词汇表，注意这里需要确保术语词典中的词也被包含在词汇表中\n",
    "        self.en_tokenizer = get_tokenizer('basic_english')\n",
    "        self.zh_tokenizer = list  # 使用字符级分词\n",
    "        \n",
    "        en_vocab = Counter(self.terminology.keys())  # 确保术语在词汇表中\n",
    "        zh_vocab = Counter()\n",
    "        \n",
    "        for en, zh in self.data:\n",
    "            en_vocab.update(self.en_tokenizer(en))\n",
    "            zh_vocab.update(self.zh_tokenizer(zh))\n",
    "        \n",
    "        # 添加术语到词汇表\n",
    "        self.en_vocab = ['<pad>', '<sos>', '<eos>'] + list(self.terminology.keys()) + [word for word, _ in en_vocab.most_common(10000)]\n",
    "        self.zh_vocab = ['<pad>', '<sos>', '<eos>'] + [word for word, _ in zh_vocab.most_common(10000)]\n",
    "        \n",
    "        self.en_word2idx = {word: idx for idx, word in enumerate(self.en_vocab)}\n",
    "        self.zh_word2idx = {word: idx for idx, word in enumerate(self.zh_vocab)}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        en, zh = self.data[idx]\n",
    "        en_tensor = torch.tensor([self.en_word2idx.get(word, self.en_word2idx['<sos>']) for word in self.en_tokenizer(en)] + [self.en_word2idx['<eos>']])\n",
    "        zh_tensor = torch.tensor([self.zh_word2idx.get(word, self.zh_word2idx['<sos>']) for word in self.zh_tokenizer(zh)] + [self.zh_word2idx['<eos>']])\n",
    "        return en_tensor, zh_tensor\n",
    "\n",
    "def collate_fn(batch):\n",
    "    en_batch, zh_batch = [], []\n",
    "    for en_item, zh_item in batch:\n",
    "        en_batch.append(en_item)\n",
    "        zh_batch.append(zh_item)\n",
    "    \n",
    "    # 对英文和中文序列分别进行填充\n",
    "    en_batch = nn.utils.rnn.pad_sequence(en_batch, padding_value=0, batch_first=True)\n",
    "    zh_batch = nn.utils.rnn.pad_sequence(zh_batch, padding_value=0, batch_first=True)\n",
    "    \n",
    "    return en_batch, zh_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T16:21:26.618878Z",
     "iopub.status.busy": "2024-07-11T16:21:26.618265Z",
     "iopub.status.idle": "2024-07-11T16:21:26.627331Z",
     "shell.execute_reply": "2024-07-11T16:21:26.626680Z",
     "shell.execute_reply.started": "2024-07-11T16:21:26.618859Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src shape: [batch_size, src_len]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded shape: [batch_size, src_len, emb_dim]\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # outputs shape: [batch_size, src_len, hid_dim]\n",
    "        # hidden shape: [n_layers, batch_size, hid_dim]\n",
    "        return outputs, hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input shape: [batch_size, 1]\n",
    "        # hidden shape: [n_layers, batch_size, hid_dim]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded shape: [batch_size, 1, emb_dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        # output shape: [batch_size, 1, hid_dim]\n",
    "        # hidden shape: [n_layers, batch_size, hid_dim]\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        # prediction shape: [batch_size, output_dim]\n",
    "        \n",
    "        return prediction, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src shape: [batch_size, src_len]\n",
    "        # trg shape: [batch_size, trg_len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        _, hidden = self.encoder(src)\n",
    "        \n",
    "        input = trg[:, 0].unsqueeze(1)  # Start token\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[:, t, :] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t].unsqueeze(1) if teacher_force else top1.unsqueeze(1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T16:21:26.628718Z",
     "iopub.status.busy": "2024-07-11T16:21:26.628390Z",
     "iopub.status.idle": "2024-07-11T16:21:26.632458Z",
     "shell.execute_reply": "2024-07-11T16:21:26.631874Z",
     "shell.execute_reply.started": "2024-07-11T16:21:26.628694Z"
    }
   },
   "outputs": [],
   "source": [
    "# 新增术语词典加载部分\n",
    "def load_terminology_dictionary(dict_file):\n",
    "    terminology = {}\n",
    "    with open(dict_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            en_term, ch_term = line.strip().split('\\t')\n",
    "            terminology[en_term] = ch_term\n",
    "    return terminology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T16:21:26.633560Z",
     "iopub.status.busy": "2024-07-11T16:21:26.633309Z",
     "iopub.status.idle": "2024-07-11T16:21:26.637977Z",
     "shell.execute_reply": "2024-07-11T16:21:26.637412Z",
     "shell.execute_reply.started": "2024-07-11T16:21:26.633541Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (src, trg) in enumerate(iterator):\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].contiguous().view(-1, output_dim)\n",
    "        trg = trg[:, 1:].contiguous().view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-11T16:21:26.640162Z",
     "iopub.status.busy": "2024-07-11T16:21:26.639873Z",
     "iopub.status.idle": "2024-07-11T16:28:24.063970Z",
     "shell.execute_reply": "2024-07-11T16:28:24.062887Z",
     "shell.execute_reply.started": "2024-07-11T16:21:26.640142Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Train Loss: 6.366\n",
      "Epoch: 02 | Train Loss: 6.087\n",
      "Epoch: 03 | Train Loss: 6.023\n",
      "Epoch: 04 | Train Loss: 5.930\n",
      "Epoch: 05 | Train Loss: 5.802\n",
      "Epoch: 06 | Train Loss: 5.682\n",
      "Epoch: 07 | Train Loss: 5.553\n",
      "Epoch: 08 | Train Loss: 5.423\n",
      "Epoch: 09 | Train Loss: 5.311\n",
      "Epoch: 10 | Train Loss: 5.201\n",
      "Epoch: 11 | Train Loss: 5.106\n",
      "Epoch: 12 | Train Loss: 5.037\n",
      "Epoch: 13 | Train Loss: 4.943\n",
      "Epoch: 14 | Train Loss: 4.851\n",
      "Epoch: 15 | Train Loss: 4.772\n",
      "Epoch: 16 | Train Loss: 4.683\n",
      "Epoch: 17 | Train Loss: 4.613\n",
      "Epoch: 18 | Train Loss: 4.526\n",
      "Epoch: 19 | Train Loss: 4.430\n",
      "Epoch: 20 | Train Loss: 4.403\n",
      "Epoch: 21 | Train Loss: 4.330\n",
      "Epoch: 22 | Train Loss: 4.252\n",
      "Epoch: 23 | Train Loss: 4.193\n",
      "Epoch: 24 | Train Loss: 4.150\n",
      "Epoch: 25 | Train Loss: 4.056\n",
      "Epoch: 26 | Train Loss: 4.022\n",
      "Epoch: 27 | Train Loss: 3.971\n",
      "Epoch: 28 | Train Loss: 3.944\n",
      "Epoch: 29 | Train Loss: 3.908\n",
      "Epoch: 30 | Train Loss: 3.807\n",
      "Epoch: 31 | Train Loss: 3.786\n",
      "Epoch: 32 | Train Loss: 3.696\n",
      "Epoch: 33 | Train Loss: 3.697\n",
      "Epoch: 34 | Train Loss: 3.640\n",
      "Epoch: 35 | Train Loss: 3.633\n",
      "Epoch: 36 | Train Loss: 3.547\n",
      "Epoch: 37 | Train Loss: 3.523\n",
      "Epoch: 38 | Train Loss: 3.495\n",
      "Epoch: 39 | Train Loss: 3.458\n",
      "Epoch: 40 | Train Loss: 3.377\n",
      "Epoch: 41 | Train Loss: 3.354\n",
      "Epoch: 42 | Train Loss: 3.320\n",
      "Epoch: 43 | Train Loss: 3.291\n",
      "Epoch: 44 | Train Loss: 3.229\n",
      "Epoch: 45 | Train Loss: 3.248\n",
      "Epoch: 46 | Train Loss: 3.214\n",
      "Epoch: 47 | Train Loss: 3.206\n",
      "Epoch: 48 | Train Loss: 3.184\n",
      "Epoch: 49 | Train Loss: 3.128\n",
      "Epoch: 50 | Train Loss: 3.101\n",
      "Total running time: 6.96 minutes\n"
     ]
    }
   ],
   "source": [
    "# 主函数\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()  # 开始计时\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    #terminology = load_terminology_dictionary('../dataset/en-zh.dic')\n",
    "    terminology = load_terminology_dictionary('../dataset/en-zh.dic')\n",
    "\n",
    "    # 加载数据\n",
    "    dataset = TranslationDataset('../dataset/train.txt',terminology = terminology)\n",
    "    # 选择数据集的前N个样本进行训练\n",
    "    N = 2000  #int(len(dataset) * 1)  # 或者你可以设置为数据集大小的一定比例，如 int(len(dataset) * 0.1)\n",
    "    subset_indices = list(range(N))\n",
    "    subset_dataset = Subset(dataset, subset_indices)\n",
    "    train_loader = DataLoader(subset_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    # 定义模型参数\n",
    "    INPUT_DIM = len(dataset.en_vocab)\n",
    "    OUTPUT_DIM = len(dataset.zh_vocab)\n",
    "    ENC_EMB_DIM = 256\n",
    "    DEC_EMB_DIM = 256\n",
    "    HID_DIM = 512\n",
    "    N_LAYERS = 2\n",
    "    ENC_DROPOUT = 0.5\n",
    "    DEC_DROPOUT = 0.5\n",
    "\n",
    "    # 初始化模型\n",
    "    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "    model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "    # 定义优化器和损失函数\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=dataset.zh_word2idx['<pad>'])\n",
    "\n",
    "    # 训练模型\n",
    "    N_EPOCHS = 50\n",
    "    CLIP = 1\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "        print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f}')\n",
    "        \n",
    "    # 在训练循环结束后保存模型\n",
    "    torch.save(model.state_dict(), './translation_model_GRU.pth')\n",
    "    \n",
    "    end_time = time.time()  # 结束计时\n",
    "\n",
    "    # 计算并打印运行时间\n",
    "    elapsed_time_minute = (end_time - start_time)/60\n",
    "    print(f\"Total running time: {elapsed_time_minute:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 在开发集上进行模型评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T16:28:24.066075Z",
     "iopub.status.busy": "2024-07-11T16:28:24.065454Z",
     "iopub.status.idle": "2024-07-11T16:28:24.089542Z",
     "shell.execute_reply": "2024-07-11T16:28:24.088872Z",
     "shell.execute_reply.started": "2024-07-11T16:28:24.066031Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sacrebleu.metrics import BLEU\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T16:28:24.091223Z",
     "iopub.status.busy": "2024-07-11T16:28:24.090629Z",
     "iopub.status.idle": "2024-07-11T16:28:24.182821Z",
     "shell.execute_reply": "2024-07-11T16:28:24.182185Z",
     "shell.execute_reply.started": "2024-07-11T16:28:24.091172Z"
    }
   },
   "outputs": [],
   "source": [
    "# 假设我们已经定义了TranslationDataset, Encoder, Decoder, Seq2Seq类\n",
    "\n",
    "def load_sentences(file_path: str) -> List[str]:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return [line.strip() for line in f]\n",
    "\n",
    "# 更新translate_sentence函数以考虑术语词典\n",
    "def translate_sentence(sentence: str, model: Seq2Seq, dataset: TranslationDataset, terminology, device: torch.device, max_length: int = 50):\n",
    "    model.eval()\n",
    "    tokens = dataset.en_tokenizer(sentence)\n",
    "    tensor = torch.LongTensor([dataset.en_word2idx.get(token, dataset.en_word2idx['<sos>']) for token in tokens]).unsqueeze(0).to(device)  # [1, seq_len]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, hidden = model.encoder(tensor)\n",
    "\n",
    "    translated_tokens = []\n",
    "    input_token = torch.LongTensor([[dataset.zh_word2idx['<sos>']]]).to(device)  # [1, 1]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        output, hidden = model.decoder(input_token, hidden)\n",
    "        top_token = output.argmax(1)\n",
    "        translated_token = dataset.zh_vocab[top_token.item()]\n",
    "        \n",
    "        if translated_token == '<eos>':\n",
    "            break\n",
    "        \n",
    "        # 如果翻译的词在术语词典中，则使用术语词典中的词\n",
    "        if translated_token in terminology.values():\n",
    "            for en_term, ch_term in terminology.items():\n",
    "                if translated_token == ch_term:\n",
    "                    translated_token = en_term\n",
    "                    break\n",
    "        \n",
    "        translated_tokens.append(translated_token)\n",
    "        input_token = top_token.unsqueeze(1)  # [1, 1]\n",
    "\n",
    "    return ''.join(translated_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T16:28:24.184359Z",
     "iopub.status.busy": "2024-07-11T16:28:24.183745Z",
     "iopub.status.idle": "2024-07-11T16:28:24.189259Z",
     "shell.execute_reply": "2024-07-11T16:28:24.188693Z",
     "shell.execute_reply.started": "2024-07-11T16:28:24.184328Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_bleu(model: Seq2Seq, dataset: TranslationDataset, src_file: str, ref_file: str, terminology,device: torch.device):\n",
    "    model.eval()\n",
    "    src_sentences = load_sentences(src_file)\n",
    "    ref_sentences = load_sentences(ref_file)\n",
    "    \n",
    "    translated_sentences = []\n",
    "    for src in src_sentences:\n",
    "        translated = translate_sentence(src, model, dataset, terminology, device)\n",
    "        translated_sentences.append(translated)\n",
    "    \n",
    "    bleu = BLEU()\n",
    "    score = bleu.corpus_score(translated_sentences, [ref_sentences])\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T16:28:24.190702Z",
     "iopub.status.busy": "2024-07-11T16:28:24.190271Z",
     "iopub.status.idle": "2024-07-11T16:28:38.051901Z",
     "shell.execute_reply": "2024-07-11T16:28:38.051204Z",
     "shell.execute_reply.started": "2024-07-11T16:28:24.190671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4 score: 0.00\n"
     ]
    }
   ],
   "source": [
    "# 主函数\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 加载术语词典\n",
    "    terminology = load_terminology_dictionary('../dataset/en-zh.dic')\n",
    "    \n",
    "    # 创建数据集实例时传递术语词典\n",
    "    dataset = TranslationDataset('../dataset/train.txt', terminology)\n",
    "    \n",
    "\n",
    "    # 定义模型参数\n",
    "    INPUT_DIM = len(dataset.en_vocab)\n",
    "    OUTPUT_DIM = len(dataset.zh_vocab)\n",
    "    ENC_EMB_DIM = 256\n",
    "    DEC_EMB_DIM = 256\n",
    "    HID_DIM = 512\n",
    "    N_LAYERS = 2\n",
    "    ENC_DROPOUT = 0.5\n",
    "    DEC_DROPOUT = 0.5\n",
    "\n",
    "    # 初始化模型\n",
    "    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "    model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "    # 加载训练好的模型\n",
    "    model.load_state_dict(torch.load('./translation_model_GRU.pth'))\n",
    "\n",
    "    # 评估BLEU分数\n",
    "    bleu_score = evaluate_bleu(model, dataset, '../dataset/dev_en.txt', '../dataset/dev_zh.txt', terminology = terminology,device = device)\n",
    "    print(f'BLEU-4 score: {bleu_score.score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 在测试集上进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T16:28:38.052996Z",
     "iopub.status.busy": "2024-07-11T16:28:38.052748Z",
     "iopub.status.idle": "2024-07-11T16:28:38.056994Z",
     "shell.execute_reply": "2024-07-11T16:28:38.056549Z",
     "shell.execute_reply.started": "2024-07-11T16:28:38.052978Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference(model: Seq2Seq, dataset: TranslationDataset, src_file: str, save_dir:str, terminology, device: torch.device):\n",
    "    model.eval()\n",
    "    src_sentences = load_sentences(src_file)\n",
    "    \n",
    "    translated_sentences = []\n",
    "    for src in src_sentences:\n",
    "        translated = translate_sentence(src, model, dataset, terminology, device)\n",
    "        #print(translated)\n",
    "        translated_sentences.append(translated)\n",
    "        #print(translated_sentences)\n",
    "\n",
    "    # 将列表元素连接成一个字符串，每个元素后换行\n",
    "    text = '\\n'.join(translated_sentences)\n",
    "\n",
    "    # 打开一个文件，如果不存在则创建，'w'表示写模式\n",
    "    with open(save_dir, 'w', encoding='utf-8') as f:\n",
    "        # 将字符串写入文件\n",
    "        f.write(text)\n",
    "\n",
    "    #return translated_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T16:28:38.058221Z",
     "iopub.status.busy": "2024-07-11T16:28:38.057875Z",
     "iopub.status.idle": "2024-07-11T16:28:52.149291Z",
     "shell.execute_reply": "2024-07-11T16:28:52.148719Z",
     "shell.execute_reply.started": "2024-07-11T16:28:38.058175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "翻译完成！文件已保存到../dataset/submit.txt\n"
     ]
    }
   ],
   "source": [
    "# 主函数\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 加载术语词典\n",
    "    terminology = load_terminology_dictionary('../dataset/en-zh.dic')\n",
    "    # 加载数据集和模型\n",
    "    dataset = TranslationDataset('../dataset/train.txt',terminology = terminology)\n",
    "\n",
    "    # 定义模型参数\n",
    "    INPUT_DIM = len(dataset.en_vocab)\n",
    "    OUTPUT_DIM = len(dataset.zh_vocab)\n",
    "    ENC_EMB_DIM = 256\n",
    "    DEC_EMB_DIM = 256\n",
    "    HID_DIM = 512\n",
    "    N_LAYERS = 2\n",
    "    ENC_DROPOUT = 0.5\n",
    "    DEC_DROPOUT = 0.5\n",
    "\n",
    "    # 初始化模型\n",
    "    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "    model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "    # 加载训练好的模型\n",
    "    model.load_state_dict(torch.load('./translation_model_GRU.pth'))\n",
    "    \n",
    "    save_dir = '../dataset/submit.txt'\n",
    "    inference(model, dataset, src_file=\"../dataset/test_en.txt\", save_dir = save_dir, terminology = terminology, device = device)\n",
    "    print(f\"翻译完成！文件已保存到{save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
