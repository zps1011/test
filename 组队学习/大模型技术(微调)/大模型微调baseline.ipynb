{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 星火大模型驱动阅读理解题库构建挑战赛baseline01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 语文问答数据制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.下列对文本相关内容和艺术特色的分析鉴赏，不正确的一项是(3分)\n",
      "A.作者在写南国的风物时，用了“那一块一块的稻田”那-堆-堆的房屋”等，语言的节奏感符合火\n",
      "车行进时的动态感。\n",
      "B.作者认为车过潭江的部分是“新宁铁路中的一段最美丽的工程”，既在于这里风景的优美，更在于\n",
      "工程体现了机械的诗意。\n",
      "C.作者认为如果只把“月夜”“ 花朝”“青山” 一类的东西当作写诗的材料，其实是不懂诗，依\n",
      "据是这些材料本身缺乏生命力.\n",
      "D.“诗应该给人以创造的喜悦，诗应该散布生命”是作者对诗的认识，也是他认为机械具有诗意的一一\n",
      "个重要前提.\n",
      "8.本文在写“机械的诗”时再写到工人，请简要分析二者之间的内在联系。(6分)\n",
      "9.这篇随笔的最后段跳转到作者在上海的生活见闻，这样写有什么好处?请结合文本简要分析.\n"
     ]
    }
   ],
   "source": [
    "# coding~\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 读取Excel文件\n",
    "df = pd.read_excel('训练集-语文.xlsx')\n",
    "df = df.replace('．', '.', regex=True)\n",
    "df = df.replace('（', '(', regex=True)\n",
    "\n",
    "\n",
    "# 读取第二行（即第三行）“选项”列的内容\n",
    "second_row_option_content = df.loc[2, '选项']\n",
    "\n",
    "# 显示第二行“选项”列的内容\n",
    "print(second_row_option_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def chinese_multiple_choice_questions(questions_with_answers):\n",
    "    # 输入的题目文本\n",
    "    text = questions_with_answers\n",
    "\n",
    "    # 正则表达式模式\n",
    "    question_pattern = re.compile(r'\\d+\\..*?(?=\\d+\\.|$)', re.DOTALL)\n",
    "    choice_pattern = re.compile(r'([A-D])\\s*(.*?)(?=[A-D]|$|\\n)', re.DOTALL)\n",
    "\n",
    "    # 找到所有问题\n",
    "    questions = question_pattern.findall(text)\n",
    "\n",
    "    # 初始化选择题和简答题列表\n",
    "    multiple_choice_questions = []\n",
    "    short_answer_questions = []\n",
    "\n",
    "        # 处理每个问题\n",
    "    for id,question in enumerate(questions):\n",
    "        # 检查是否是选择题\n",
    "        if re.search(r'[A-D]', question):\n",
    "            \n",
    "            choices = choice_pattern.findall(question)\n",
    "            question_text = re.split(r'\\n', question.split('(')[0])[0]\n",
    "            \n",
    "            \n",
    "            pattern_question = re.compile(r'(\\d+)\\.(.*)')\n",
    "            matches_question = str(id+1)+'.'+ pattern_question.findall(question_text)[0][1] # 取出问题后重排序\n",
    "            # print(str(id+1)+'.'+matches_question)\n",
    "            \n",
    "            multiple_choice_questions.append({\n",
    "                'question': matches_question,\n",
    "                'choices': choices\n",
    "            })\n",
    "        else:\n",
    "            short_answer_questions.append(question.strip())\n",
    "    return multiple_choice_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "questions_list = []\n",
    "for data_id in range(len(df[:3])):\n",
    "    second_row_option_content = df.loc[data_id, '选项']\n",
    "    questions_list.append(chinese_multiple_choice_questions(second_row_option_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def chinese_multiple_choice_answers(questions_with_answers):\n",
    "    questions_with_answers = questions_with_answers.replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "    \n",
    "    # print(questions_with_answers)\n",
    "    # 使用正则表达式匹配答案\n",
    "    choice_pattern = re.compile(r'(\\d+)\\.([A-Z]+)')\n",
    "    short_pattern = re.compile(r'(\\d+)\\.([^A-Z]+)')\n",
    "\n",
    "    # 找到所有匹配的答案\n",
    "    choice_matches = choice_pattern.findall(questions_with_answers)\n",
    "    short_matches = short_pattern.findall(questions_with_answers)\n",
    "\n",
    "    # 将匹配结果转换为字典\n",
    "    choice_answers = {int(index): answer for index, answer in choice_matches}\n",
    "    short_answers = {int(index): answer for index, answer in short_matches}\n",
    "\n",
    "    # 按序号重新排序\n",
    "    sorted_choice_answers = sorted(choice_answers.items())\n",
    "    sorted_short_answers = sorted(short_answers.items())\n",
    "    \n",
    "    answers = []\n",
    "\n",
    "    # 输出结果\n",
    "    \n",
    "    # print(\"选择题答案：\")\n",
    "    for id in range(len(sorted_choice_answers)):\n",
    "        answers.append(f\"{id+1}. {sorted_choice_answers[id][1]}\")\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.B\n",
      "5.窗子既是指现实世界中的窗子，可以是铁纱窗，或者是玻璃窗；窗子又是指隔绝自己生活与他人世界的象征。\n",
      "有的人坐在窗子里面，有的人行走在窗子外面，而一扇窗子隔绝出来的，是两个截然不同的世界，窗外的人固然不了解窗里的人，窗里的人，也永远不能了解窗外的人。\n",
      "6.你、我的代表了两种不同的人生视角，观看自己生活的视角和观看他人生活的视角。窗外是劳作、奔波、挣扎、穷苦，窗内是奢侈、悠闲、烦闷、无聊。这是两个世界，两种生活。蕴含着作者的态度：窗里窗外是两个世界，窗外的人无法理解窗内，窗内的人也无法走进窗外，我们只能以一个旁观者的角度对待世界，不要以为自己真正的解了什么而私下满足，“天知道那是罪过”。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1. B']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取第二行（即第三行）“选项”列的内容\n",
    "second_row_option_content = df.loc[60, '答案']\n",
    "\n",
    "# 显示第二行“选项”列的内容\n",
    "print(second_row_option_content)\n",
    "\n",
    "\n",
    "chinese_multiple_choice_answers(second_row_option_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['答案_processed'] = df['答案'].map(chinese_multiple_choice_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_prompt_cn(text):\n",
    "    prompt = f'''\n",
    "    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择题，包含题目选项，以及对应的答案，注意：不⽤给出原文，每道题由1个问题和4个选项组成，仅存在1个正确答案，请严格按照要求执行。 阅读文本主要是中文，你出的题目需要满足以下要点，紧扣文章内容且题干和答案为中文：\n",
    "    \n",
    "    ### 回答要求\n",
    "    (1)理解文中重要概念的含义\n",
    "    (2)理解文中重要句子的含意\n",
    "    (3)分析论点、论据和论证方法\n",
    "    \n",
    "    \n",
    "    ### 阅读文本\n",
    "    {text}\n",
    "    '''\n",
    "    \n",
    "    return prompt   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_cn(df): \n",
    "    res_input = []\n",
    "    res_output = []\n",
    "    for id in range(len(df)):\n",
    "        data_options = df.loc[id, '选项']\n",
    "        data_answers = df.loc[id,'答案']\n",
    "        data_prompt = df.loc[id,'阅读文本']\n",
    "        data_options = chinese_multiple_choice_questions(data_options)\n",
    "        data_answers = chinese_multiple_choice_answers(data_answers)\n",
    "        data_prompt = get_prompt_cn(data_prompt)\n",
    "        # print(data_options)\n",
    "        # print(data_answers)\n",
    "        \n",
    "        if(len(data_answers)==len(data_options)):\n",
    "            res = ''\n",
    "            for id_,question in enumerate(data_options):\n",
    "                res += f'''\n",
    "{question['question']}?\n",
    "                '''+'\\n'\n",
    "                for choise in question['choices']:\n",
    "                    res = res+ choise[0] + choise[1]+ '\\n'\n",
    "                res = res + '答案:' + str(data_answers[id_].split('.')[-1])  + '\\n'\n",
    "            res_output.append(res)\n",
    "            res_input.append(data_prompt)\n",
    "        # break\n",
    "    return res_input,res_output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cn_input,cn_output = process_cn(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cn_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 英语问答制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21. What is an advantage of MacBike?\n",
      "A. It gives children a discount.\n",
      "B. It of offers many types of bikes.\n",
      "C. It organizes free cycle tours.\n",
      "D. It has over 2,500 rental shops.\n",
      "22. How much do you pay for renting a bike with hand brake and three gears for two days?\n",
      "A. €15.75.\n",
      "B. €19.50.\n",
      "C. €22.75.\n",
      "D. €29.50.\n",
      "23. Where does the guided city tour start?\n",
      "A. The Gooyer, Windmill.\n",
      "C. Heineken Brewery.\n",
      "B. The Skinny Bridge.\n",
      "D. D.m Square.\n"
     ]
    }
   ],
   "source": [
    "# coding~\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 读取Excel文件\n",
    "df = pd.read_excel('训练集-英语.xlsx')\n",
    "df = df.replace('．', '.', regex=True).replace('А.', 'A.', regex=True).replace('В.', 'B.', regex=True).replace('С.', 'C.', regex=True).replace('D.', 'D.', regex=True)\n",
    "# df = df.replace('（', '(', regex=True)\n",
    "\n",
    "# 读取第二行（即第三行）“选项”列的内容\n",
    "second_row_option_content = df.loc[0, '选项']\n",
    "\n",
    "# 显示第二行“选项”列的内容\n",
    "print(second_row_option_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_whitespace_and_newlines(input_string):\n",
    "    # 使用str.replace()方法删除空格和换行符\n",
    "    result = input_string.replace(\" \", \"\").replace(\"\\n\", \"\").replace(\".\", \"\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 示例文本\n",
    "text = \"\"\"\n",
    "32. B. The underlying logic of the effect.                                                   33.D. estimates were not fully independent.\n",
    "34.C. The discussion process.            35.D. Approving.\n",
    "\"\"\"\n",
    "def get_answers(text):\n",
    "    text = remove_whitespace_and_newlines(text)\n",
    "    # 正则表达式模式\n",
    "    pattern = re.compile(r'(\\d)\\s*([A-D])')\n",
    "\n",
    "    # 查找所有匹配项\n",
    "    matches = pattern.findall(text)\n",
    "    res = []\n",
    "    # 打印结果\n",
    "    for match in matches:\n",
    "        number_dot, first_letter = match\n",
    "        res.append(first_letter)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'D', 'D', 'B']\n"
     ]
    }
   ],
   "source": [
    "# 示例输入\n",
    "input_string = \"28. A. It is simple and plain.              29. D. Influential.                                30. D.33%.                                             31. B. Male chefs on TV programmes.\"\n",
    "res = get_answers(input_string)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': ' What is an advantage of MacBike?', 'options': {'A': 'A. It gives children a discount.', 'B': 'B. It of offers many types of bikes.', 'C': 'C. It organizes free cycle tours.', 'D': 'D. It has over 2,500 rental shops.'}}\n",
      "{'question': ' How much do you pay for renting a bike with hand brake and three gears for two days?', 'options': {'A': 'A. €15.75.', 'B': 'B. €19.50.', 'C': 'C. €22.75.', 'D': 'D. €29.50.'}}\n",
      "{'question': ' Where does the guided city tour start?', 'options': {'A': 'A. The Gooyer, Windmill.', 'B': 'B. The Skinny Bridge.', 'C': 'C. Heineken Brewery.', 'D': 'D. D.m Square.'}}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 示例文本\n",
    "text = second_row_option_content\n",
    "\n",
    "def get_questions(text):\n",
    "    text = text.replace('\\n', '  ')+'  '\n",
    "    # print(text)\n",
    "    # 正则表达式模式\n",
    "    pattern = re.compile(r'(\\d+\\..*?)(A\\..*?\\s{2})([B-D]\\..*?\\s{2})([B-D]\\..*?\\s{2})(D\\..*?\\s{2})', re.DOTALL)\n",
    "\n",
    "    # 查找所有匹配项\n",
    "    matches = pattern.findall(text)\n",
    "\n",
    "    # 存储结果的字典列表\n",
    "    questions_dict_list = []\n",
    "\n",
    "    # 打印结果\n",
    "    for match in matches:\n",
    "        question, option1, option2, option3, option4 = match\n",
    "        pattern_question = re.compile(r'(\\d+)\\.(.*)')\n",
    "        question_text = pattern_question.findall(question.strip())[0][1]\n",
    "        \n",
    "        # 提取选项字母和内容\n",
    "        options = {option1[0]: option1, option2[0]: option2, option3[0]: option3, option4[0]: option4}\n",
    "        \n",
    "        question_dict = {\n",
    "            'question': question_text,\n",
    "            'options': {\n",
    "                'A': options.get('A', '').strip(),\n",
    "                'B': options.get('B', '').strip(),\n",
    "                'C': options.get('C', '').strip(),\n",
    "                'D': options.get('D', '').strip()\n",
    "            }\n",
    "        }\n",
    "        questions_dict_list.append(question_dict)\n",
    "    return questions_dict_list\n",
    "\n",
    "# 调用函数并打印结果\n",
    "questions = get_questions(text)\n",
    "for q in questions:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_prompt_en(text):\n",
    "    prompt = f'''\n",
    "    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择题，包含题目选项，以及对应的答案，注意：不⽤给出原文，每道题由1个问题和4个选项组成，仅存在1个正确答案，请严格按照要求执行。\n",
    "The reading text is mainly in English. The questions and answers you raised need to be completed in English for at least the following points:\n",
    "    \n",
    "    ### 回答要求\n",
    "    (1)Understanding the main idea of the main idea.\n",
    "    (2)Understand the specific information in the text.\n",
    "    (3)infering the meaning of words and phrases from the context\n",
    "    \n",
    "    \n",
    "    ### 阅读文本\n",
    "    {text}\n",
    "    '''\n",
    "    \n",
    "    return prompt   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_en(df): \n",
    "    res_input = []\n",
    "    res_output = []\n",
    "    for id in range(len(df)):\n",
    "        data_options = df.loc[id, '选项']\n",
    "        data_answers = df.loc[id,'答案']\n",
    "        data_prompt = df.loc[id,'阅读文本']\n",
    "        data_options = get_questions(data_options)\n",
    "        data_answers = get_answers(data_answers)\n",
    "        data_prompt = get_prompt_en(data_prompt)\n",
    "        # print(data_options)\n",
    "        # print(data_answers)\n",
    "\n",
    "        if(len(data_answers)==len(data_options)):\n",
    "            res = ''\n",
    "            for id,question in enumerate(data_options):\n",
    "                res += f'''\n",
    "                {id+1}.{question['question']}\n",
    "                {question['options']['A']}\n",
    "                {question['options']['B']}\n",
    "                {question['options']['C']}\n",
    "                {question['options']['D']}\n",
    "                answer:{data_answers[id]}\n",
    "                '''+'\\n'\n",
    "            res_output.append(res)\n",
    "            res_input.append(data_prompt)\n",
    "    return res_input,res_output\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "en_input,en_output = process_en(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...</td>\n",
       "      <td>\\n1.下列关于原文内容的理解和分析,正确的一项是?\\n                \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...</td>\n",
       "      <td>\\n1.下列对原文相关内容的理解和分析,正确的一项是?\\n                \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...</td>\n",
       "      <td>\\n1.下列对文本相关内容和艺术特色的分析鉴赏，不正确的一项是?\\n            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...</td>\n",
       "      <td>\\n1.下列关于原文内容的理解和分析，不正确的一-项是?\\n                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...</td>\n",
       "      <td>\\n1.下列对原文相关内容的理解和分析，不正确的一项是?\\n                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>\\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...</td>\n",
       "      <td>\\n                1. What makes the applicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>\\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...</td>\n",
       "      <td>\\n                1. Where is the Welsh Proms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>\\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...</td>\n",
       "      <td>\\n                1. How did the cockatoos get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>\\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...</td>\n",
       "      <td>\\n                1. Which of the following be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>\\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...</td>\n",
       "      <td>\\n                1. What is the first paragra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input  \\\n",
       "0    \\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...   \n",
       "1    \\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...   \n",
       "2    \\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...   \n",
       "3    \\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...   \n",
       "4    \\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...   \n",
       "..                                                 ...   \n",
       "147  \\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...   \n",
       "148  \\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...   \n",
       "149  \\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...   \n",
       "150  \\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...   \n",
       "151  \\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择...   \n",
       "\n",
       "                                                output  \n",
       "0    \\n1.下列关于原文内容的理解和分析,正确的一项是?\\n                \\n...  \n",
       "1    \\n1.下列对原文相关内容的理解和分析,正确的一项是?\\n                \\...  \n",
       "2    \\n1.下列对文本相关内容和艺术特色的分析鉴赏，不正确的一项是?\\n            ...  \n",
       "3    \\n1.下列关于原文内容的理解和分析，不正确的一-项是?\\n                ...  \n",
       "4    \\n1.下列对原文相关内容的理解和分析，不正确的一项是?\\n                ...  \n",
       "..                                                 ...  \n",
       "147  \\n                1. What makes the applicatio...  \n",
       "148  \\n                1. Where is the Welsh Proms ...  \n",
       "149  \\n                1. How did the cockatoos get...  \n",
       "150  \\n                1. Which of the following be...  \n",
       "151  \\n                1. What is the first paragra...  \n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 将两个列表转换为DataFrame\n",
    "df_new = pd.DataFrame({'input': cn_input+cn_input[:30]+en_input+en_input[:20], 'output': cn_output+cn_output[:30]+en_output+en_output[:20]})\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL 文件已生成\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# 打开一个文件用于写入 JSONL，并设置编码为 UTF-8\n",
    "with open('output.jsonl', 'w', encoding='utf-8') as f:\n",
    "    # 遍历每一行并将其转换为 JSON\n",
    "    for index, row in df_new.iterrows():\n",
    "        row_dict = row.to_dict()\n",
    "        row_json = json.dumps(row_dict, ensure_ascii=False,)\n",
    "        # 将 JSON 字符串写入文件，并添加换行符\n",
    "        f.write(row_json + '\\n')\n",
    "\n",
    "# 打印确认信息\n",
    "print(\"JSONL 文件已生成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.模型微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拿着微调文件快到飞书文档学习如何使用平台微调！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.本地测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T08:58:59.124811Z",
     "iopub.status.busy": "2024-08-08T08:58:59.124281Z",
     "iopub.status.idle": "2024-08-08T09:04:14.610890Z",
     "shell.execute_reply": "2024-08-08T09:04:14.609063Z",
     "shell.execute_reply.started": "2024-08-08T08:58:59.124779Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/spark-ai-python/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting spark_ai_python\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/1f/13/293b42d649332d49b2e570f1b60d90123dfd3f145aa43374d442631c875c/spark_ai_python-0.4.1-py3-none-any.whl (345 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.5/345.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp>3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from spark_ai_python) (3.9.5)\n",
      "Requirement already satisfied: httpx in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from spark_ai_python) (0.27.0)\n",
      "Collecting jsonpatch (from spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-index/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-index<0.11.0,>=0.10.24 (from spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/67/c1/7666a9aafb725fee504a12c11a27766c220b8cde3a341ffdc6ed825bb88d/llama_index-0.10.64-py3-none-any.whl (6.8 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-index-vector-stores-chroma/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-index-vector-stores-chroma<0.2.0,>=0.1.6 (from spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/bb/30/fde34609cb2451f21a7e2c3a381778ab163f93395b85f8fe3ef52baea021/llama_index_vector_stores_chroma-0.1.10-py3-none-any.whl (5.0 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from spark_ai_python) (1.6.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from spark_ai_python) (24.1)\n",
      "Requirement already satisfied: pydantic in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from spark_ai_python) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from spark_ai_python) (1.0.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from spark_ai_python) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from spark_ai_python) (2.32.3)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/tenacity/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tenacity (from spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/b6/cb/b86984bed139586d01532a587464b5805f12e397594f19f931c4c2fbfa61/tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting websocket-client<2.0.0,>=1.7.0 (from spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/5a/84/44687a29792a70e111c5c477230a72c4b957d88d16141199bf9acb7537a3/websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: websockets in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from spark_ai_python) (11.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from aiohttp>3.3->spark_ai_python) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from aiohttp>3.3->spark_ai_python) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from aiohttp>3.3->spark_ai_python) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from aiohttp>3.3->spark_ai_python) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from aiohttp>3.3->spark_ai_python) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from aiohttp>3.3->spark_ai_python) (4.0.3)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-index-agent-openai/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/c2/9a/9a327ff664e4904b6806f716bf705041d3015b99b12568872833df10b18f/llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-index-cli/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/fc/74/58a8f8b33bc709947ed08f29055967f49efa995aac59f45d7c4443814d0d/llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-index-core/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-index-core<0.11.0,>=0.10.64 (from llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f9/66/0c0c3bc88097d89e58ba823f1e4446ee86bef164499a3dea160744aa7eb7/llama_index_core-0.10.64-py3-none-any.whl (15.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-index-embeddings-openai/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/0b/ee/68b58b7485c82aadd301ae33f1c6071c04ecfccc9c0bdd599a7dd1ee96b4/llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-index-indices-managed-llama-cloud/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ec/0f/b1d0e685a2994d56bc09382e5933d293f6b158ecc842fd2357d6436b2f37/llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/02/0a/0da9d27b0c3b074c1be1151ff4a4558f077c93df463310adfb47d193dde2/llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-index-llms-openai/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-index-llms-openai<0.2.0,>=0.1.27 (from llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/55/6c/6c33b13e85d8a19c621b9b7f101cb990d4c24f8e2cd39d1fff04c2d8066f/llama_index_llms_openai-0.1.29-py3-none-any.whl (11 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-index-multi-modal-llms-openai/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/54/8f/6f6719bd284459a1e5bb283a7a25fc20e9609d6e423e340b304efcc48f81/llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-index-program-openai/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ae/6f/f7998c2cfd7de3a33276ed8cabc291291043a45642524c502768d340ebbb/llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/2d/22/39f3ac5702b0e8ffd4d5a383c7cb2da0eb60f63b95f739345e79b66bf977/llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-index-readers-file/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/47/00/4f3dde2368275e9dad8c9f4daa11205806dd6ac5d3db7b7a9f11e21db37c/llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-index-readers-llama-parse/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-index-readers-llama-parse>=0.1.2 (from llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/c7/97/d3a73b62cdef72b1d32527d90f4d32432beb2f48861c8177c5f08d46b974/llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/chromadb/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting chromadb<0.6.0,>=0.4.0 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/80/4c/ee62b19a8daeed51e3c88c84b7da6047a74b786e598be3592b67a286d419/chromadb-0.5.5-py3-none-any.whl (584 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from httpx->spark_ai_python) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from httpx->spark_ai_python) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from httpx->spark_ai_python) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from httpx->spark_ai_python) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from httpx->spark_ai_python) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from httpcore==1.*->httpx->spark_ai_python) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/71/92/5e77f98553e9e75130c78900d000368476aed74276eb8ae8796f65f00918/jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from pydantic->spark_ai_python) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from pydantic->spark_ai_python) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from pydantic->spark_ai_python) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests->spark_ai_python) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests->spark_ai_python) (2.2.2)\n",
      "Collecting build>=1.0.3 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/e2/03/f3c8ba0a6b6e30d7d18c40faab90807c9bb5e9a1e3b2fe2008af624a9c97/build-1.2.1-py3-none-any.whl (21 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/chroma-hnswlib/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting chroma-hnswlib==0.7.6 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3a/6d/27826180a54df80dbba8a4f338b022ba21c0c8af96fd08ff8510626dee8f/chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fastapi>=0.95.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.111.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.30.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/6c/5f/24cb22118db0e11703b6b80ef9f982eadde21eb585c3a769719e48dce893/posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: onnxruntime>=1.14.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.18.1)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/opentelemetry-api/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opentelemetry-api>=1.2.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/e3/a7/6322d1d7a1fb926e8b99208c27730f21217da2f1e0e11dab48a78a0427a4/opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/opentelemetry-exporter-otlp-proto-grpc/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/4d/0c/e4473692fec8076008c7926dfcef7223fc6d2785f04ad9d8402347a4eba9/opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/opentelemetry-instrumentation-fastapi/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a5/29/a97842d6dfa679bf0f3624ce1ea3458eb185befd536cafe580daa9ab68ae/opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl (11 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/opentelemetry-sdk/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opentelemetry-sdk>=1.2.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/92/f1/a9b550d0f9c049653dd2eab45cecf8fe4baa9795ed143d87834056ffabaf/opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/tokenizers/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tokenizers>=0.13.2 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/fc/7e/794850f99752d1811952722c18652a5c0125b0ef595d9ed069d00da9a5db/tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/c7/2c/94ed7b91db81d61d7096ac8f2d325ec562fc75e35f3baea8749c85b28784/PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (4.66.4)\n",
      "Collecting overrides>=7.3.1 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/2c/ab/fc8290c6a4c722e5514d80f62b2dc4c4df1a68a41d1364e625c35990fcf3/overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (6.4.0)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/grpcio/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting grpcio>=1.58.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a5/57/f03b02c4fad8b72539ab04b8b524782e071c89a2d9c182d60b5d9ded41d7/grpcio-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/bcrypt/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3e/d0/31938bb697600a04864246acde4918c4190a938f891fd11883eaaf41327a/bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.12.3)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/62/a1/2027ddede72d33be2effc087580aeba07e733a7360780ae87226f1f91bd8/kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/03/87/4b01a43336bd506478850d1bc3d180648b2d26b4acf1fc4bf1df72bf562f/mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.10.6)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/openai/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/7c/ae/2a66f072b9733b3287807f76bca53913aa448c7ac1d70b08cd9e79af7675/openai-1.40.3-py3-none-any.whl (360 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.7/360.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/sqlalchemy/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3b/94/db0bc142f448627638a2962afae54c520697119c0d6e23ebd36a7c472c8f/SQLAlchemy-2.0.32-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/68/69/1bcf70f81de1b4a9f21b3a62ec0c83bdff991c88d6cc2267d02408457e88/dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python) (2024.5.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python) (3.3)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/nltk/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/46/79/9daa0fcc1b3ccd51012fe733f9375c1201704eaaaae3fae03ea397cda780/nltk-3.8.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python) (10.4.0)\n",
      "Collecting tenacity (from spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d2/3f/8ba87d9e287b9d385a02a7114ddcef61b26f86411e121c9003eb509a1773/tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/e7/8c/7d1007557b343d5cf18349802e94d3a14397121e9105b4661f8cd753f9bf/tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting wrapt (from llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/49/83/b40bc1ad04a868b5b5bcec86349f06c1ee1ea7afe51dc3e46131e4f39308/wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-cloud/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/0b/c3/e377c515e16230a1db2b6c445eed444be151b2aa82b6b8b2dbeac026530d/llama_cloud-0.0.13-py3-none-any.whl (169 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/b1/fe/e8c672695b37eecc5cbf43e1d0638d88d66ba3a44c4d321c796f4e59167f/beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/pypdf/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3c/60/eccdd92dd4af3e4bea6d6a342f7588c618a15b9bec4b968af581e498bcc4/pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a3/cf/0fea4f4ba3fc2772ac2419278aa9f6964124d4302117d61bc055758e000c/striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/llama-parse/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/98/21/1702c91141c0c06692fde4305b873f06ff1649f622666d6be8fbc7da03aa/llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from anyio->httpx->spark_ai_python) (1.2.1)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/4c/f3/038b302fdfbe3be7da016777069f26ceefe11a681055ea1f7817546508e3/soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ae/f3/431b9d5fe7d14af7a32340792ef43b8a714e7726f1d7b69cc4e8e7a3f1d7/pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/97/75/10a9ebee3fd790d20926a90a2547f0bf78f371b2f13aa822c759680ca7b9/tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.0.4)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.1.4)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.0.9)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (5.10.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.9.0.post0)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/google-auth/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/60/57/0f37c6f35847e26b7bea7d5e4f069cf037fd792cf8b67206311761e7bb92/google_auth-2.33.0-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python) (2024.5.15)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.20.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.12.1)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/jiter/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/41/6a/c038077509d67fe876c724bfe9ad15334593851a7def0d84518172bdd44a/jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata<=8.0.0,>=6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (8.0.0)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/googleapis-common-protos/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/02/48/87422ff1bddcae677fb6f58c97f5cfc613304a5e8ce2c3662760199c0a84/googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/opentelemetry-exporter-otlp-proto-common/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/25/2f/0f7e0a73fd901c9abc6ea680d7f19a803dac830c450f21e1123d3a3ec488/opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/opentelemetry-proto/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/15/f4/66a3892eea913cded9bac0fdd3fb1a412fa2da8eb50014ec87a52648444a/opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/opentelemetry-instrumentation-asgi/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ba/d9/c74cb6d69589cc97d856cb3f427dfcef37ec16f9564586290c9c075d9020/opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl (15 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/opentelemetry-instrumentation/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/1f/6a/be31a84ddd13e9018fcca6885e4710f227eb0fd06eda1896da67287faa2e/opentelemetry_instrumentation-0.47b0-py3-none-any.whl (29 kB)\n",
      "\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/opentelemetry-semantic-conventions/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/00/c2/ca5cef8e4cd8eec5a95deed95ec3f6005e499fd9d17ca08731ced03a6921/opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Skipping page https://mirror.baidu.com/pypi/simple/opentelemetry-util-http/ because the GET request got Content-Type: application/octet-stream. The only supported Content-Types are application/vnd.pypi.simple.v1+json, application/vnd.pypi.simple.v1+html, and text/html\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/10/7e/98749e14a4e3f4db8bc016e6b42aba40e4d934baeb8767b8658a99d0dfac/opentelemetry_util_http-0.47b0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (69.5.1)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/39/e3/893e8757be2612e6c266d9bb58ad2e3651524b5b40cf56761e985a28b13e/asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/24/35/945d5b10648fec9b20bcc6df8952d20bb3bba76413cd71c1fdbee98f5616/greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.23.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (13.7.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.22.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/96/d7/f318261e6ccbba86bdf626e07cd850981508fdaec52cfcdc4ac1030327ab/marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.64->llama-index<0.11.0,>=0.10.24->spark_ai_python) (2024.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.6.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (5.3.3)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/13/68/8906226b15ef38e71dc926c321d2fe99de8048e9098b5dfd38343011c886/pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/49/97/fa78e3d2f65c02c8e1268b9aba606569fe97f6c8f7c2d74394553347c145/rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.15.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (3.19.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (2.18.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python) (0.1.2)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.6->spark_ai_python)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/23/7e/5f50d07d5e70a2addbccd90ac2950f81d1edd0783630651d9268d7f1db49/pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=41af92621479391805d98044d3a053e7e61f71c8c16c1c7f4d1091a9f4ae44b4\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/72/22/e9/22e7a498a5a6f391ae627013a1bcc011dac57bb1a41d4f9274\n",
      "Successfully built pypika\n",
      "Installing collected packages: striprtf, pypika, monotonic, mmh3, dirtyjson, wrapt, websocket-client, tomli, tenacity, soupsieve, pyproject_hooks, pypdf, pyasn1, overrides, opentelemetry-util-http, opentelemetry-proto, oauthlib, nltk, mypy-extensions, marshmallow, jsonpointer, jiter, grpcio, greenlet, googleapis-common-protos, distro, chroma-hnswlib, bcrypt, backoff, asgiref, typing-inspect, tiktoken, SQLAlchemy, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-exporter-otlp-proto-common, jsonpatch, deprecated, build, beautifulsoup4, tokenizers, opentelemetry-api, openai, llama-cloud, google-auth, dataclasses-json, opentelemetry-semantic-conventions, opentelemetry-instrumentation, llama-index-legacy, llama-index-core, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, chromadb, llama-index-vector-stores-chroma, llama-index-question-gen-openai, llama-index, spark_ai_python\n",
      "Successfully installed SQLAlchemy-2.0.32 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 beautifulsoup4-4.12.3 build-1.2.1 chroma-hnswlib-0.7.6 chromadb-0.5.5 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 google-auth-2.33.0 googleapis-common-protos-1.63.2 greenlet-3.0.3 grpcio-1.65.4 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-30.1.0 llama-cloud-0.0.13 llama-index-0.10.64 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.64 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.29 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.33 llama-index-readers-llama-parse-0.1.6 llama-index-vector-stores-chroma-0.1.10 llama-parse-0.4.9 marshmallow-3.21.3 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 nltk-3.8.2 oauthlib-3.2.2 openai-1.40.3 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-instrumentation-0.47b0 opentelemetry-instrumentation-asgi-0.47b0 opentelemetry-instrumentation-fastapi-0.47b0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-util-http-0.47b0 overrides-7.7.0 posthog-3.5.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 pypdf-4.3.1 pypika-0.48.9 pyproject_hooks-1.1.0 requests-oauthlib-2.0.0 rsa-4.9 soupsieve-2.5 spark_ai_python-0.4.1 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.7.0 tokenizers-0.20.0 tomli-2.0.1 typing-inspect-0.9.0 websocket-client-1.8.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade spark_ai_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T09:04:23.909303Z",
     "iopub.status.busy": "2024-08-08T09:04:23.907765Z",
     "iopub.status.idle": "2024-08-08T09:04:24.000952Z",
     "shell.execute_reply": "2024-08-08T09:04:23.999795Z",
     "shell.execute_reply.started": "2024-08-08T09:04:23.909256Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = {\"input\": \"\\n    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择题，包含题目选项，以及对应的答案，注意：不⽤给出原文，每道题由1个问题和4个选项组成，仅存在1个正确答案，请严格按照要求执行。\\nThe reading text is mainly in English. The questions and answers you raised need to be completed in English for at least the following points:\\n    \\n    ### 回答要求\\n    (1)Understanding the main idea of the main idea.\\n    (2)Understand the specific information in the text.\\n    (3)infering the meaning of words and phrases from the context\\n    \\n    \\n    ### 阅读文本\\n    Bike Rental & Guided Tours Welcome to Amsterdam, welcome to MacBike. You see much more from the seat of a bike! Cycling is the most\\neconomical, sustainable and fun way to explore the city, with its beautiful canals, parks, squares and countless lights.\\nYou can also bike along lovely landscapes outside of Amsterdam.\\nWhy MacBike MacBike has been around for almost 30 years and is the biggest bicycle rental company in Amsterdam. With over 2,500 bikes stored in our five rental shops at strategic locations, we make sure there is always a bike available for you. We offer the newest bicycles in a wide variety, including basic bikes with foot brake (AU 4), bikes with hand\\nbrake and gears (HI-I'4), bikes with child seats, and children's bikes.                                                                       Price: 1 hour, 3 hours, 1 day(24hours), Each additional day                                                                                          Hand Brake, Three Gears: €7.50, €11.00, €14.75, €8.00                                                       Foot Brake, No Gears: €5.00, €7.50, €9.75, €6.00                     The 2.5-hour tour covers the Gooyer Windmill, the Skinny Bridge, the Rijksmuseum, Heineken Brewery and much more. The tour departs from D.m Square every hour on the hour, starting at 1:00 pm every day. You can buy\\nyour ticket in a MacBike shop or book online.\\n    \", \"output\": \"\\n                1. What is an advantage of MacBike?\\n                A. It gives children a discount.\\n                B. It of offers many types of bikes.\\n                C. It organizes free cycle tours.\\n                D. It has over 2,500 rental shops.\\n                answer:B\\n                \\n\\n                2. How much do you pay for renting a bike with hand brake and three gears for two days?\\n                A. €15.75.\\n                B. €19.50.\\n                C. €22.75.\\n                D. €29.50.\\n                answer:D\\n                \\n\\n                3. Where does the guided city tour start?\\n                A. The Gooyer, Windmill.\\n                B. The Skinny Bridge.\\n                C. Heineken Brewery.\\n                D. D.m Square.\\n                answer:D\\n                \\n\"}\n",
    "prompt = prompt['input']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![./data/p1.png](./p1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T09:06:50.724244Z",
     "iopub.status.busy": "2024-08-08T09:06:50.723022Z",
     "iopub.status.idle": "2024-08-08T09:06:58.641737Z",
     "shell.execute_reply": "2024-08-08T09:06:58.640734Z",
     "shell.execute_reply.started": "2024-08-08T09:06:50.724176Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the most economical way to explore Amsterdam?\n",
      "A. By car\n",
      "B. By walking\n",
      "C. By bike\n",
      "D. By boat\n",
      "Answer: C. By bike\n"
     ]
    }
   ],
   "source": [
    "from sparkai.llm.llm import ChatSparkLLM, ChunkPrintHandler\n",
    "from sparkai.core.messages import ChatMessage\n",
    "\n",
    "SPARKAI_URL = 'wss://xingchen-api.cn-huabei-1.xf-yun.com/v1.1/chat'\n",
    "#星火认知大模型调用秘钥信息，请结合飞书文档，前往讯飞微调控制台（https://training.xfyun.cn/modelService）查看\n",
    "SPARKAI_APP_ID = ''\n",
    "SPARKAI_API_SECRET = ''\n",
    "SPARKAI_API_KEY = ''\n",
    "serviceId = ''  \n",
    "resourceId = ''\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    spark = ChatSparkLLM(\n",
    "        spark_api_url=SPARKAI_URL,\n",
    "        spark_app_id=SPARKAI_APP_ID,\n",
    "        spark_api_key=SPARKAI_API_KEY,\n",
    "        spark_api_secret=SPARKAI_API_SECRET,\n",
    "        spark_llm_domain=serviceId,\n",
    "        model_kwargs={\"patch_id\": resourceId},\n",
    "        streaming=False,\n",
    "    )\n",
    "    messages = [ChatMessage(\n",
    "        role=\"user\",\n",
    "        content=prompt\n",
    "    )]\n",
    "    handler = ChunkPrintHandler()\n",
    "    a = spark.generate([messages], callbacks=[handler])\n",
    "    print(a.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.模型提交"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这里测试就结束啦，到飞书看看怎么提交吧~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('python35-paddle120-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "09f0dbf7b1569c1ab842ae2f41770fe6aa1b54326d081112fa5944b99abb5899"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
